{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7eec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PySpark Setup Cell ---\n",
    "import os, sys, findspark\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = r\"E:\\Coding\\BDA-PySpark\\spark-3.4.1-bin-hadoop3\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e742eb",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e55134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "import torch\n",
    "import threading\n",
    "import re\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943426a",
   "metadata": {},
   "source": [
    "Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51784110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SentimentDetectionPipeline\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723b28a",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35ce2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_path = r\"hdfs://localhost:9000/user/adarsh/realtime_pipeline/filtered_batches\"\n",
    "output_dir = r\"E:\\Coding\\BDA-PySpark\\realtime-pipeline\\results_spark\"\n",
    "final_output_file = os.path.join(output_dir, \"sentiment_flags_spark.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcac5af",
   "metadata": {},
   "source": [
    "# Model setup\n",
    "1. Loads a multilingual sentiment model (positive, negative, neutral) for text classification.\n",
    "2. thread-local object is used -> Spark worker thread loads the model once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da125e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_udf(text):\n",
    "    # Thread local for model reuse\n",
    "    local_model = threading.local()\n",
    "    def get_model():\n",
    "        if not hasattr(local_model, \"model\"):\n",
    "            device = 0 if torch.cuda.is_available() else -1\n",
    "            local_model.model = pipeline(\n",
    "                \"text-classification\",\n",
    "                model=\"tabularisai/multilingual-sentiment-analysis\",\n",
    "                framework=\"pt\",\n",
    "                device=device,\n",
    "                return_all_scores=True,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "        return local_model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1779e2",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "1. Splits very long comments into chunks of â‰¤400 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c4102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def minimal_clean_sentiment(text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        text = text.strip()\n",
    "        if len(text.split()) < 5:\n",
    "            return \"\"\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text\n",
    "\n",
    "    def split_long_text(text, max_words=400):\n",
    "        words = text.split()\n",
    "        if len(words) <= max_words:\n",
    "            return [text]\n",
    "        return [' '.join(words[i:i + max_words]) for i in range(0, len(words), max_words) if ' '.join(words[i:i + max_words]).strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e6a44",
   "metadata": {},
   "source": [
    "# Prediction + aggregation\n",
    "1. Runs inference batch-wise\n",
    "2. per batch ,picks the highest confidence label per chunk\n",
    "3. `{label, score}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33124f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_udf(text):\n",
    "    local_model = threading.local()\n",
    "    \n",
    "    def get_model():\n",
    "        if not hasattr(local_model, \"model\"):\n",
    "            device = 0 if torch.cuda.is_available() else -1\n",
    "            local_model.model = pipeline(\n",
    "                \"text-classification\",\n",
    "                model=\"tabularisai/multilingual-sentiment-analysis\",\n",
    "                framework=\"pt\",\n",
    "                device=device,\n",
    "                return_all_scores=True,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "        return local_model.model\n",
    "\n",
    "    def minimal_clean_sentiment(text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        text = text.strip()\n",
    "        if len(text.split()) < 5:\n",
    "            return \"\"\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text\n",
    "\n",
    "    def split_long_text(text, max_words=400):\n",
    "        words = text.split()\n",
    "        if len(words) <= max_words:\n",
    "            return [text]\n",
    "        return [\n",
    "            ' '.join(words[i:i + max_words])\n",
    "            for i in range(0, len(words), max_words)\n",
    "            if ' '.join(words[i:i + max_words]).strip()\n",
    "        ]\n",
    "\n",
    "    def aggregate_chunk_sentiments(chunk_results):\n",
    "        if not chunk_results:\n",
    "            return {'label': 'neutral', 'score': 0.0}\n",
    "        if len(chunk_results) == 1:\n",
    "            return chunk_results[0]\n",
    "        sentiment_weights = {}\n",
    "        for result in chunk_results:\n",
    "            label = result['label']\n",
    "            score = result['score']\n",
    "            sentiment_weights[label] = sentiment_weights.get(label, 0.0) + score\n",
    "        final_label = max(sentiment_weights, key=sentiment_weights.get)\n",
    "        final_score = sentiment_weights[final_label] / len(chunk_results)\n",
    "        return {'label': final_label, 'score': final_score}\n",
    "\n",
    "    try:\n",
    "        text = minimal_clean_sentiment(text)\n",
    "        if not text:\n",
    "            return {'label': 'neutral', 'score': 0.0}\n",
    "        chunks = split_long_text(text, max_words=400)\n",
    "        chunk_preds = []\n",
    "        model = get_model()\n",
    "        for i in range(0, len(chunks), 32):\n",
    "            batch = chunks[i:i + 32]\n",
    "            batch_preds = model(batch, truncation=True, max_length=512)\n",
    "            for pred_group in batch_preds:\n",
    "                if isinstance(pred_group, list):\n",
    "                    best_pred = max(pred_group, key=lambda x: x['score'])\n",
    "                    chunk_preds.append(best_pred)\n",
    "                else:\n",
    "                    chunk_preds.append(pred_group)\n",
    "        final_result = aggregate_chunk_sentiments(chunk_preds)\n",
    "        return {'label': final_result['label'], 'score': final_result['score']}\n",
    "    except Exception as e:\n",
    "        print(f\"UDF error: {e}\")\n",
    "        return {'label': 'error', 'score': 0.0}\n",
    "    \n",
    "    \n",
    "result_schema = StructType([\n",
    "    StructField(\"label\", StringType(), True),\n",
    "    StructField(\"score\", FloatType(), True)\n",
    "])\n",
    "\n",
    "sentiment_predict_udf = udf(sentiment_udf, result_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd4c95",
   "metadata": {},
   "source": [
    "cleaning temporary folder recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598ffb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_single_csv(df, output_path):\n",
    "    temp_dir = output_path + \"_temp\"\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    # Only output required columns\n",
    "    df.select(\"comment\", \"sentiment\", \"score\") \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"header\", True) \\\n",
    "        .csv(temp_dir)\n",
    "    part_file = glob.glob(os.path.join(temp_dir, 'part-*.csv'))\n",
    "    if not part_file:\n",
    "        raise FileNotFoundError(\"No part file found in temp directory\")\n",
    "    part_file = part_file[0]\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    shutil.move(part_file, output_path)\n",
    "    shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b03f90",
   "metadata": {},
   "source": [
    "Main Function + saving file to as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819f35a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 322 comments\n",
      "Output saved to E:\\Coding\\BDA-PySpark\\realtime-pipeline\\results_spark as sentiment_flags_spark.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_spark = spark.read.text(input_path).toDF(\"comment\")\n",
    "    df_spark = df_spark.filter(\"length(comment) > 10\")\n",
    "    print(f\"Processing {df_spark.count()} comments\")\n",
    "\n",
    "    df_result = df_spark.withColumn(\"sentiment_result\", sentiment_predict_udf(col(\"comment\")))\n",
    "    df_result = df_result.withColumn(\"sentiment\", col(\"sentiment_result.label\")) \\\n",
    "                         .withColumn(\"score\", col(\"sentiment_result.score\")) \\\n",
    "                         .drop(\"sentiment_result\")\n",
    "    save_single_csv(df_result, final_output_file)\n",
    "    print(f\"Output saved to {output_dir} as sentiment_flags_spark.csv\")\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PySpark 3.10)",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

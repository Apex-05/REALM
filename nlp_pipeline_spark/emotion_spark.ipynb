{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e339bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PySpark Setup Cell ---\n",
    "import os, sys, findspark\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = r\"E:\\Coding\\BDA-PySpark\\spark-3.4.1-bin-hadoop3\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55102938",
   "metadata": {},
   "source": [
    "`Hugging Face transformers` library imported for emotion detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49df0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "import torch\n",
    "import threading\n",
    "\n",
    "# Import transformer pipeline\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9b243",
   "metadata": {},
   "source": [
    "Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2c178a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"EmotionDetectionPipeline\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bba8ce",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a40bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDFS or local input path\n",
    "input_path = \"hdfs://localhost:9000/user/adarsh/realtime_pipeline/filtered_batches\"\n",
    "\n",
    "# Output CSV path\n",
    "output_dir = r\"E:\\Coding\\BDA-PySpark\\realtime-pipeline\\results_spark\"\n",
    "final_output_file = os.path.join(output_dir, \"emotion_flags_spark.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d95bc3",
   "metadata": {},
   "source": [
    "1. The emotion_udf function performs emotion detection on each comment using the\\\n",
    "  Hugging Face model j-hartmann\n",
    "/emotion-english-distilroberta-base, loaded efficiently via a thread-local setup.\n",
    "2. It cleans and splits long texts into smaller chunks, processes them in batches, and then \\\n",
    "aggregates predictions to find the dominant emotion and its confidence score.\n",
    "3. Finally, the output structure (label, score) is defined with a Spark schema and\\\n",
    " registered as a UDF so Spark can apply it in parallel across all comments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4a33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_udf(text):\n",
    "    # Thread local avoids re-loading model\n",
    "    local_model = threading.local()\n",
    "    def get_model():\n",
    "        if not hasattr(local_model, \"model\"):\n",
    "            device = 0 if torch.cuda.is_available() else -1\n",
    "            local_model.model = pipeline(\n",
    "                \"text-classification\",\n",
    "                model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "                framework=\"pt\",\n",
    "                device=device,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "        return local_model.model\n",
    "    try:\n",
    "        model = get_model()\n",
    "        # Clean, filter, and chunk\n",
    "        if not isinstance(text, str) or len(text.strip().split()) < 5:\n",
    "            return {'label': 'neutral', 'score': 0.0}\n",
    "        text = text.strip()\n",
    "        words = text.split()\n",
    "        max_words = 400\n",
    "        if len(words) <= max_words:\n",
    "            chunks = [text]\n",
    "        else:\n",
    "            chunks = [' '.join(words[i:i + max_words]) for i in range(0, len(words), max_words)]\n",
    "        batch_size = 32\n",
    "        chunk_preds = []\n",
    "        for i in range(0, len(chunks), batch_size):\n",
    "            batch = chunks[i:i + batch_size]\n",
    "            preds = model(batch, truncation=True, max_length=512)\n",
    "            chunk_preds.extend(preds)\n",
    "        # Aggregate results\n",
    "        if not chunk_preds:\n",
    "            return {'label': 'neutral', 'score': 0.0}\n",
    "        emotion_weights = {}\n",
    "        for result in chunk_preds:\n",
    "            label = result['label']\n",
    "            score = result['score']\n",
    "            emotion_weights[label] = emotion_weights.get(label, 0.0) + score\n",
    "        final_label = max(emotion_weights, key=emotion_weights.get)\n",
    "        final_score = emotion_weights[final_label] / len(chunk_preds)\n",
    "        return {'label': final_label, 'score': final_score}\n",
    "    except Exception as e:\n",
    "        print(f\"Emotion detection error: {e}\")\n",
    "        return {'label': 'error', 'score': 0.0}\n",
    "\n",
    "emotion_schema = StructType([\n",
    "    StructField(\"label\", StringType(), True),\n",
    "    StructField(\"score\", FloatType(), True)\n",
    "])\n",
    "emotion_predict_udf = udf(emotion_udf, emotion_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d484513",
   "metadata": {},
   "source": [
    "1. Saving to .csv file\n",
    "2. cleaning of temporary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "982573af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_single_csv(df, output_path):\n",
    "    temp_dir = output_path + \"_temp\"\n",
    "    import shutil, glob, os\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    df.select(\"comment\", \"emotion\", \"score\") \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"header\", True) \\\n",
    "        .csv(temp_dir)\n",
    "    part_file = glob.glob(os.path.join(temp_dir, 'part-*.csv'))\n",
    "    if not part_file:\n",
    "        raise FileNotFoundError(\"No part file found in temp directory\")\n",
    "    part_file = part_file[0]\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "    shutil.move(part_file, output_path)\n",
    "    shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e314fa",
   "metadata": {},
   "source": [
    "Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b5b76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 322 comments\n",
      "Output saved to {output_dir} as emotion_flags_spark.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Read comments from HDFS or local text files\n",
    "    df_spark = spark.read.text(input_path).toDF(\"comment\")\n",
    "    df_spark = df_spark.filter(\"length(comment) > 10\")\n",
    "    print(f\"Processing {df_spark.count()} comments\")\n",
    "\n",
    "    # Run distributed emotion detection\n",
    "    df_result = df_spark.withColumn(\"emotion_result\", emotion_predict_udf(col(\"comment\")))\n",
    "    df_result = df_result.withColumn(\"emotion\", col(\"emotion_result.label\")) \\\n",
    "                         .withColumn(\"score\", col(\"emotion_result.score\")) \\\n",
    "                         .drop(\"emotion_result\")\n",
    "\n",
    "    # Save as a single CSV\n",
    "    save_single_csv(df_result.select(\"comment\", \"emotion\", \"score\"), final_output_file)\n",
    "\n",
    "    # Print summary to console\n",
    "    print(f\"Output saved to {output_dir} as emotion_flags_spark.csv\")\n",
    "\n",
    "\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PySpark 3.10)",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
